{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8kkhS-UgJAR"
      },
      "source": [
        "We will explore the following strategies\n",
        "\n",
        "- Better Prompting\n",
        "- Agentic RAG with Tools\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1KvMtf54l0d"
      },
      "source": [
        "#### Install the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "E0iJpMMXJVsS"
      },
      "outputs": [],
      "source": [
        "# ! pip install langchain-community tiktoken langchain-openai langchainhub chromadb langchain langgraph tavily-python langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "7_PP8tTSSInU"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.tools import tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9c37cLnSrbg"
      },
      "source": [
        "#### Enter GROQ API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "1Q2MlMeDE1Aw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"your_api_key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oeckxFBcc0E"
      },
      "source": [
        "#### Load Connection to LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "vHa9LMOfcOCV"
      },
      "outputs": [],
      "source": [
        "llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyLHUeW2IhRU"
      },
      "source": [
        "#### Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "M4qP9O9mJrZD"
      },
      "outputs": [],
      "source": [
        "# Data related with Agents, Prompt Engineering and LLMs\n",
        "\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "]\n",
        "\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=250, chunk_overlap=0\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf0pKYK3SS1d"
      },
      "source": [
        "#### Use a Sentence-Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "pAIPOzl-QjlU"
      },
      "outputs": [],
      "source": [
        "embedding_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZXosht8Sd4n"
      },
      "source": [
        "#### Create Vector Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "UzqATwRzIgwM"
      },
      "outputs": [],
      "source": [
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    collection_name=\"rag-chroma\",\n",
        "    embedding=embedding_model\n",
        ")\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3hZ_O32as0x"
      },
      "source": [
        "## Better Prompting for Consistent Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htTiJ8RTgiAG"
      },
      "source": [
        "#### Problematic RAG Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "JcHrMo7tF2dR"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"You are an assistant for question-answering tasks.\n",
        "            Give an answer to the following question with the context provided\n",
        "\n",
        "            Question:\n",
        "            {question}\n",
        "\n",
        "            Context:\n",
        "            {context}\n",
        "\n",
        "            Answer:\n",
        "         \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "63wYkFyqKYLc"
      },
      "outputs": [],
      "source": [
        "# Post-processing\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "ywSPAVgsLOSn"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"You are an assistant for question-answering tasks.\n",
        "            Give an answer to the following question with the context provided\n",
        "\n",
        "            Question:\n",
        "            {question}\n",
        "\n",
        "            Context:\n",
        "            {context}\n",
        "\n",
        "            Answer:\n",
        "         \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWK8cwXWTGmC"
      },
      "source": [
        "#### The question below is not part of the provided context, but the LLM generates the answer based on its pretraining knowledge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zntL-LfYKOGG",
        "outputId": "f7033df0-7aee-4661-d8af-aceec1428883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The research paper \"Attention Is All You Need\" was published in 2017. It was written by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. The paper introduced the Transformer model, which relies entirely on self-attention mechanisms to process input sequences. Although the provided context does not mention this specific paper, it is a well-known publication in the field of natural language processing and machine learning.\n"
          ]
        }
      ],
      "source": [
        "question = \"When was the research paper: Attention Is All You Need was pubilshed?\"\n",
        "docs = retriever.get_relevant_documents(question)\n",
        "docs = format_docs(docs)\n",
        "\n",
        "# Chain\n",
        "rag_chain = prompt_template | llm | StrOutputParser()\n",
        "\n",
        "# Run\n",
        "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "print(generation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVc9olR5gmP6"
      },
      "source": [
        "#### Better RAG Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "6VhrwTZcHKed"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"You are an assistant for question-answering tasks.\n",
        "            Use the following pieces of retrieved context to answer the question.\n",
        "            If no context is present or if you don't know the answer, just say that you don't know.\n",
        "            Do not make up the answer unless it is there in the provided context.\n",
        "\n",
        "            Question:\n",
        "            {question}\n",
        "\n",
        "            Context:\n",
        "            {context}\n",
        "\n",
        "            Answer:\n",
        "         \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d56z4f5TW7P"
      },
      "source": [
        "##### After updating the prompt, we are now receiving the correct response, as the LLM is no longer relying on its pre-trained knowledge to answer the question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDRUhBGHLbK4",
        "outputId": "ac073591-c739-4a55-fdbe-c93cb125b888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't know. The provided context does not mention the research paper \"Attention Is All You Need\" or its publication date.\n"
          ]
        }
      ],
      "source": [
        "question = \"When was the research paper: Attention Is All You Need was pubilshed?\"\n",
        "docs = retriever.get_relevant_documents(question)\n",
        "docs = format_docs(docs)\n",
        "\n",
        "# Chain\n",
        "rag_chain = prompt_template | llm | StrOutputParser()\n",
        "\n",
        "# Run\n",
        "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "print(generation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeLmkbOIaoWF"
      },
      "source": [
        "## Agentic RAG with Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucWRRI3QztL2"
      },
      "source": [
        "#### Enter Tavily Search Tool API Key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "R2h8vdQNVNjZ"
      },
      "outputs": [],
      "source": [
        "os.environ['TAVILY_API_KEY'] = \"your_api_key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ36nHepgrgp"
      },
      "source": [
        "#### Setup Search Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "ALfCdvXqVO09"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def search_web(query: str) -> list:\n",
        "    \"\"\"Search the web for a query.\"\"\"\n",
        "    tavily_tool = TavilySearchResults(max_results=3,\n",
        "                                      search_depth='advanced',\n",
        "                                      max_tokens=10000)\n",
        "    results = tavily_tool.invoke(query)\n",
        "    return [doc['content'] for doc in results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "N7jzQYr7VesD",
        "outputId": "0f92777e-e774-469e-c9f9-9334e3656223"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'When was the research paper: Attention Is All You Need was pubilshed?'"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBuA2jXoVdL_",
        "outputId": "4db2c0a2-30fd-41cf-fc85-cc7f05105168"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['An illustration of main components of the transformer model from the paper \"Attention Is All You Need\" [1] is a 2017 landmark [2] [3] research paper in machine learning authored by eight scientists working at Google.The paper introduced a new deep learning architecture known as the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al. [4] It is considered a',\n",
              " 'published in 2017 an influential research paper titled \"Attention Is All You Need\" at the Neural Information Processing Systems (NeurIPS) conference that introduced the Transformer architecture, a novel Neural Network (NN) model for Natural Language Processing (NLP) tasks. With the Transformer, researchers created a simple network architecture based only on attention mechanisms, without recurrence and convolutions. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.\" [3] To capture long-term dependencies and contextual relationships between words in a sentence, the model uses attention mechanism to enable neural networks to selectively focus on specific parts of the input sequence.',\n",
              " 'The paper introduced the ‚ÄúTransformer‚Äù architecture for the first time, it was a new neural network model for natural language processing (NLP) tasks, which primarily uses attention mechanism to process input sequences. The authors of the paper argue that attention bases approaches are better than traditional approaches to NLP tasks, as they allow the model to selectively attend to different parts of the input sequence, which allows us to capture the contextual relationships between words in text. \"Attention Is All You Need\"\\xa0is a ground-breaking paper that introduced the Transformer architecture, a neural network model for NLP tasks that relies on attention mechanisms to process input sequences.']"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search_web(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4Khdw6Agvrn"
      },
      "source": [
        "#### Bind Tools to LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "YD4r_QxZN551"
      },
      "outputs": [],
      "source": [
        "tools = [search_web]\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools, tool_choice=\"auto\")  # Ensure function calling is enabled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2TlF4AwgyJT"
      },
      "source": [
        "#### Better RAG Prompt with Tool Calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "X-5xXrygWyLL"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"You are an assistant for question-answering tasks.\n",
        "            Use the following pieces of retrieved context to answer the question.\n",
        "            If no context is present or if you don't know the answer,\n",
        "            check and see if you can use the tools available to you to get the answer.\n",
        "\n",
        "            Question:\n",
        "            {question}\n",
        "\n",
        "            Context:\n",
        "            {context}\n",
        "\n",
        "            Answer:\n",
        "         \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMpmOo-rL0bo",
        "outputId": "1907c250-9ed7-49b4-f664-69f0dbf45576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='<function=search_web{\"query\": \"publication date of research paper Attention Is All You Need\"}</function>' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 1102, 'total_tokens': 1125, 'completion_time': 0.083636364, 'prompt_time': 0.058822957, 'queue_time': 0.261708122, 'total_time': 0.142459321}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ca0059abb', 'finish_reason': 'stop', 'logprobs': None} id='run-7d39daac-a13a-42b4-b278-ba21e8ce9b5c-0' usage_metadata={'input_tokens': 1102, 'output_tokens': 23, 'total_tokens': 1125}\n"
          ]
        }
      ],
      "source": [
        "question = \"When was the research paper: Attention Is All You Need was pubilshed?\"\n",
        "docs = retriever.get_relevant_documents(question)\n",
        "docs = format_docs(docs)\n",
        "\n",
        "rag_chain = prompt_template | llm_with_tools\n",
        "\n",
        "response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvmXXv_YXQgc",
        "outputId": "3fe1f107-797d-4a43-a77f-c9f9be4240b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='The provided context does not explicitly mention the types of agent memory. However, it does mention \"memory\" as a component of generative agents, which combines LLM with memory, planning, and reflection mechanisms. Additionally, it mentions a \"Memory stream\" which is a long-term memory module that records a comprehensive list of agents\\' experience in natural language.\\n\\nThe context also discusses human brain memory, mentioning the following types:\\n\\n1. Sensory Memory: \\n   - Iconic memory (visual)\\n   - Echoic memory (auditory)\\n   - Haptic memory (touch)\\n\\nSince the question asks about the types of agent memory and the provided context does not give a clear answer, I will not provide any additional information.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 146, 'prompt_tokens': 1181, 'total_tokens': 1327, 'completion_time': 0.530909091, 'prompt_time': 0.117476252, 'queue_time': 0.024661195999999996, 'total_time': 0.648385343}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3884478861', 'finish_reason': 'stop', 'logprobs': None} id='run-a950627c-af25-4333-9083-993eab7bcca5-0' usage_metadata={'input_tokens': 1181, 'output_tokens': 146, 'total_tokens': 1327}\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the types of agent memory?\"\n",
        "docs = retriever.get_relevant_documents(question)\n",
        "docs = format_docs(docs)\n",
        "\n",
        "rag_chain = prompt_template | llm_with_tools\n",
        "\n",
        "response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGB14NL5g94n"
      },
      "source": [
        "#### Simple Agentic RAG with Tool Calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "VzsRkX2AXGgl"
      },
      "outputs": [],
      "source": [
        "def agentic_rag(question, context):\n",
        "  tool_call_map = {'search_web' : search_web}\n",
        "  response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "\n",
        "  # if response content is present then we have our answer\n",
        "  if response.content:\n",
        "    print('Answer is in retrieved context')\n",
        "    answer = response.content\n",
        "\n",
        "  # if no response content present then call search tool\n",
        "  elif response.tool_calls:\n",
        "    print('Answer not in context, trying to use tools')\n",
        "    tool_call = response.tool_calls[0]\n",
        "    selected_tool = tool_call_map[tool_call[\"name\"].lower()]\n",
        "    print(f\"Calling tool: {tool_call['name']}\")\n",
        "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
        "    context = '\\n\\n'.join(tool_output)\n",
        "    response = rag_chain.invoke({'context': context, 'question': question})\n",
        "    answer = response.content\n",
        "\n",
        "  # no answer found from web search also\n",
        "  else:\n",
        "    answer = 'No answer found'\n",
        "\n",
        "  print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBm8mJSpXjNd",
        "outputId": "19bcb543-3d8e-4f7f-a8e2-efcb311b6472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer is in retrieved context\n",
            "The provided context does not explicitly mention the types of agent memory. However, it does mention \"memory\" as a component of generative agents, which includes a \"memory stream\" that is a long-term memory module. Additionally, the context provides information on human memory types, but it is unclear if these types apply to agent memory. To provide a more accurate answer, I would need to search for information on agent memory types. \n",
            "\n",
            "<function=search_web{\"query\": \"types of agent memory\"}</function>\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the types of agent memory?\"\n",
        "docs = retriever.get_relevant_documents(question)\n",
        "docs = format_docs(docs)\n",
        "\n",
        "agentic_rag(question, docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Zdn-quXjhY",
        "outputId": "7311d42e-76fb-4c4d-9e39-8dd79eba8ad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer not in context, trying to use tools\n",
            "Calling tool: search_web\n",
            "The research paper \"Attention Is All You Need\" was published in 2017, as indicated by the arXiv identifier \"arXiv:1706.03762\" which corresponds to June 2017, and it was presented at the 31st International Conference on Neural Information Processing Systems (NIPS'17).\n"
          ]
        }
      ],
      "source": [
        "question = \"When was the research paper: Attention Is All You Need was pubilshed?\"\n",
        "\n",
        "docs = retriever.get_relevant_documents(question)\n",
        "docs = format_docs(docs)\n",
        "\n",
        "agentic_rag(question, docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "5szFRgnsK5CS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
